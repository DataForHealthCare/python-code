{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unit Testing in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- What is a unit test?\n",
    "    - Definition\n",
    "    - Use case(s)\n",
    "    - Best practice(s)\n",
    "    - Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Strategies for implementation\n",
    "    - Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To write, or not to write?\n",
    "    - Approaches to testing\n",
    "    - When to omit unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objectives (cont.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Benefits of unit testing\n",
    "- Pytest framework introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Databricks unit tests\n",
    "    - Notebook setup (single, multiple cases)\n",
    "- Demo\n",
    "    - Python shared module "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Takeaways\n",
    "    - Start with AI\n",
    "    - Follow best practices\n",
    "    - Modularize tests\n",
    "    - DevOps Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unit Test Definition\n",
    "\n",
    "A unit test is a block of code that verifies the accuracy of a smaller, isolated block of application code, typically a function or method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use Case(s)\n",
    "\n",
    "The unit test is designed to check that the block of code runs as expected, according to the developerâ€™s theoretical logic behind it. The unit test is only capable of interacting with the block of code via inputs and captured asserted (true or false) output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import ipytest\n",
    "ipytest.autoconfig()\n",
    "\n",
    "# User defined function\n",
    "def integer_addition(no_one, no_two): return no_one + no_two\n",
    "\n",
    "# Unit test example for 'def integer_addition'\n",
    "def test_integer_addition(): result = integer_addition(no_one=15, no_two=15); assert result == 30\n",
    "\n",
    "# Run command line tests \n",
    "ipytest.run('-vv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Best Practice\n",
    "\n",
    "It's a software development best practice to write software as small, functional units then write a unit test for each code unit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Structure testcases:* Arrange, Act and Assert\n",
    "\n",
    "- Arrange, set up the conditions for the test. (inputs and targets)\n",
    "- Act, call the function or method. (focus on taregt behavior)\n",
    "- Assert, assert the end condition is true. (expected outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def test_integer_addition():\n",
    "    \n",
    "    # Arrange\n",
    "    no_one = 30\n",
    "    no_two = 100\n",
    "\n",
    "    # Act\n",
    "    result = integer_addition(no_one, no_two)\n",
    "    \n",
    "    # Assert\n",
    "    assert result == 130\n",
    "\n",
    "\n",
    "ipytest.run('-vv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Strategies for Unit Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Logic Checks*: Does the system perform the right calculations and follow the right path through the code given a correct, expected input? Are all paths through the code covered by the given inputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def list_of_integers(sequence: list) -> list: return {_ for _ in sequence}\n",
    "\n",
    "def test_list_of_integers():\n",
    "    \n",
    "    # Arrange\n",
    "    sequence = [_ for _ in range(10)]\n",
    "\n",
    "    # Act\n",
    "    result = list_of_integers(sequence)\n",
    "    \n",
    "    # Assert\n",
    "    assert type(result) is list\n",
    "\n",
    "\n",
    "ipytest.run('-vv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Boundary Checks*: How will the system respond to typical inputs, edge cases, or invalid input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def list_of_integers(sequence: list) -> list: return [_ for _ in sequence]\n",
    "\n",
    "def test_list_of_integers_invalid_input():\n",
    "    \n",
    "    # Arrange - ASSERTION ERROR for invalid input (generator vs. list)\n",
    "    sequence = (_ for _ in range(10))\n",
    "\n",
    "    # Act\n",
    "    result = list_of_integers(sequence)\n",
    "    \n",
    "    # Assert\n",
    "    assert type(sequence) is list\n",
    "\n",
    "\n",
    "ipytest.run('-vv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Error Handling*: When there are errors in inputs, how does the system respond?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "def list_of_integers(sequence: list) -> list: return [_ for _ in sequence]\n",
    "\n",
    "def test_list_of_integers_exception():\n",
    "    \n",
    "    # Arrange\n",
    "    sequence = [str(_) for _ in range(10)]\n",
    "\n",
    "    # Act\n",
    "    result = list_of_integers(sequence)\n",
    "    \n",
    "    # Assert  \n",
    "    value = sequence \n",
    "    try:\n",
    "        with pytest.raises(ValueError) as exc_info:\n",
    "            if not all(type(_) == int for _ in value): \n",
    "                raise ValueError(\"Only integers are allowed in the input list\")\n",
    "        assert exc_info.value is ValueError\n",
    "    except:\n",
    "        print()\n",
    "\n",
    "\n",
    "ipytest.run('-vv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Object-Oriented Checks*: If the state of any persistent objects is changed by running the code, is the object updated correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class KeyBoard:\n",
    "    KEYS = 105\n",
    "\n",
    "    def __init__(self, color):\n",
    "        self._color = color\n",
    "\n",
    "    @property\n",
    "    def color(self):\n",
    "        return self._color\n",
    "    \n",
    "    @color.setter\n",
    "    def color(self, color):\n",
    "        self._color = color\n",
    "\n",
    "class TestKeyBoard:\n",
    "\n",
    "    def test_color(self):\n",
    "        c = KeyBoard('blue')\n",
    "        assert ('blue', 100) == (c.color, c.KEYS)\n",
    "\n",
    "\n",
    "ipytest.run('-vv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## To Write, or Not to Write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Test-driven development (TDD): A software methodology emphasizing writing tests before writing code.\n",
    "    TDD Cycle: Create unit test -> Run the test -> Write code -> Repeat test -> Refactor code -> Repeat cycle\n",
    "\n",
    "- Traditional testing: Writing unit tests after the software has been created.\n",
    "\n",
    "- DevOps efficiency: Tests are ran automatically in the CI/CD pipeline to ensure code quality as changes to software occur over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When Not to Write "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Consider omitting unit testing when the following factors occur: \n",
    "    - Time contraints are present.\n",
    "    - Applications focused on look and feel rather than logic. (UI/UX) \n",
    "    - Legacy codebases. \n",
    "    - Environments with rapidly evolving requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Benefits of Unit Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Debugging lense: Reduction in debugging time by pinpointing where errors in the code appear.\n",
    "- Automatic documentation: Unit tests act as form of documentation.\n",
    "- Expectations roadmap for refactoring: Saves refactoring time in the TDD cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PyTest Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Auto-discovery of tests: Pytest will recognize tests by naming convention. Example, 'test_' + filename or filename + '_test'.\n",
    "- Rich assertion introspection: Human-readble reports to identify where the tests failed.\n",
    "- Support parameterized and fixture-based testing: \n",
    "    - Pass multiple arguments into a single test vs. writing individual tests for each case.\n",
    "    - Fixtures are reusable functions to modularize tests. Dependency Injection (fixture function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Databricks Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Start with AI: Utilize the Databricks assistant to quickly generate unit tests, then refactor as needed.\n",
    "- Follow best practices: Minimum one test per entity (function, method). Write unit tests first.\n",
    "- Modularize tests: Identify reuasble tests for a customizable library, utilize fixtures and repeatable variable arguments.\n",
    "- DevOps automation: Look automize the unit tests before pushing changes to a branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametrize Unit Tests\n",
    "@pytest.mark.parametrize(\n",
    "        'product, name',\n",
    "        [\n",
    "            ('individual', 'patient')\n",
    "        ]\n",
    ")\n",
    "def test_healthplan(product, name):\n",
    "    assert ...\n",
    "\n",
    "# Parametrize Fixtures\n",
    "@pytest.fixture(params=(\n",
    "    \"name\",\n",
    "    \"product\"\n",
    "))\n",
    "def my_settings(request):\n",
    "    return {\"name\": request.param}\n",
    "\n",
    "# Pytest Fixture\n",
    "@pytest.fixture\n",
    "def default_values() -> dict:\n",
    "    default = {\n",
    "        'name': 'patient',\n",
    "        'product': 'group'\n",
    "    }\n",
    "    return default\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
